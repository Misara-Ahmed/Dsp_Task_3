{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import signal\n",
    "\n",
    "import librosa\n",
    "import librosa.display as DSP\n",
    "import librosa as lr\n",
    "from tempfile import mktemp\n",
    "import imagehash\n",
    "from PIL import Image\n",
    "\n",
    "import pylab\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "import os\n",
    "import wave\n",
    "import time\n",
    "import pickle\n",
    "import warnings\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from scipy.io.wavfile import read\n",
    "import python_speech_features as mfcc\n",
    "from sklearn.mixture import GaussianMixture \n",
    "from sklearn.metrics import f1_score\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_delta(array):\n",
    "   \n",
    "    rows, cols = array.shape\n",
    "    # print(rows)\n",
    "    # print(cols)\n",
    "    deltas = np.zeros((rows,20))\n",
    "    N = 2\n",
    "    for i in range(rows):\n",
    "        index = []\n",
    "        j = 1\n",
    "        while j <= N:\n",
    "            if i-j < 0:\n",
    "                first =0\n",
    "            else:\n",
    "                first = i-j\n",
    "            if i+j > rows-1:\n",
    "                second = rows-1\n",
    "            else:\n",
    "                second = i+j \n",
    "            index.append((second,first))\n",
    "            j+=1\n",
    "        deltas[i] = ( array[index[0][0]]-array[index[0][1]] + (2 * (array[index[1][0]]-array[index[1][1]])) ) / 10\n",
    "    return deltas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python_speech_features in c:\\users\\misara\\anaconda3\\lib\\site-packages (0.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install python_speech_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(audio,rate):\n",
    "       \n",
    "    mfcc_feature = mfcc.mfcc(audio, rate, 0.025, 0.01, 20, nfft = 2205, appendEnergy = True)    \n",
    "    mfcc_feature = preprocessing.scale(mfcc_feature)\n",
    "#     print(mfcc_feature)\n",
    "    delta = calculate_delta(mfcc_feature)\n",
    "    combined = np.hstack((mfcc_feature, delta)) \n",
    "    return combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "lstFolders = ['Door', 'Close', 'Book','Window']\n",
    "for lst in lstFolders:\n",
    "    listFiles = glob.glob(r\"./WordData/{}\\*\".format(lst))\n",
    "    features = np.asarray(())\n",
    "    finishCounter = len(listFiles)\n",
    "    counter = 1\n",
    "    for file in listFiles:\n",
    "        try:\n",
    "            audio, sr = librosa.load(file)\n",
    "            vector = extract_features(audio, sr)\n",
    "            \n",
    "            if features.size == 0:\n",
    "                features = vector\n",
    "            else:\n",
    "                features = np.vstack((features, vector))\n",
    "                \n",
    "            X_test.append(vector)\n",
    "            y_test.append(lstFolders.index(lst))\n",
    "                \n",
    "            counter += 1\n",
    "            if(counter == finishCounter):\n",
    "                gmm = GaussianMixture(n_components = 6, max_iter = 200, covariance_type='diag', n_init = 3)\n",
    "                gmm.fit(features)\n",
    "                \n",
    "                # dumping the trained gaussian model\n",
    "                picklefile = lst + \".joblib\"\n",
    "                joblib.dump(gmm, picklefile) \n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm_files = [ i + '.joblib' for i in ['Door', 'Close', 'Book','Window']]\n",
    "\n",
    "models    = [joblib.load(fname) for fname in gmm_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_y = []\n",
    "y = []\n",
    "for i in X_test:\n",
    "    log_likelihood = np.zeros(len(models)) \n",
    "    for j in range(len(models)):\n",
    "        gmm = models[j] \n",
    "        scores = np.array(gmm.score(i))\n",
    "        log_likelihood[j] = scores.sum()\n",
    "    y.append(log_likelihood)\n",
    "#     print(y)\n",
    "    winner = np.argmax(log_likelihood)\n",
    "    final_y.append(winner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8771929824561403"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(final_y, y_test, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "[-24.58938295 -26.41731086 -22.15808788 -19.51936613]\n"
     ]
    }
   ],
   "source": [
    "file = r'./WordData/Window/my-rec22.wav'\n",
    "audio, sr = librosa.load(file)\n",
    "vector = extract_features(audio, sr)\n",
    "log_likelihood = np.zeros(len(models)) \n",
    "for i in range(len(models)):\n",
    "    gmm    = models[i] \n",
    "    scores = np.array(gmm.score(vector))\n",
    "    log_likelihood[i] = scores.sum()\n",
    "y.append(log_likelihood)\n",
    "winner = np.argmax(log_likelihood)\n",
    "print(winner)\n",
    "print(log_likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "f544ce1a915a9875fad91c894e2c0bcad4b7a79945aa6027ef3ad27810072aa6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

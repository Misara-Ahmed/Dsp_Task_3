{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa as librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "import numpy as np\n",
    "import csv\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report\n",
    "import librosa\n",
    "from sklearn.svm import SVC \n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "header = 'filename rmse spectral_centroid spectral_bandwidth rolloff zero_crossing_rate'\n",
    "\n",
    "for i in range(1, 40):\n",
    "    header += f' mfcc{i}'\n",
    "header = header.split()\n",
    "# print('CSV Header: ', header)\n",
    "file = open(\"data.csv\", 'w', newline='')\n",
    "writer = csv.writer(file)\n",
    "writer.writerow(header)\n",
    "file.close()\n",
    "\n",
    "\n",
    "def writeCsv(data):\n",
    "    file = open(\"data.csv\", 'a', newline='')\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(data.split(\",\"))\n",
    "    file.close()\n",
    "\n",
    "\n",
    "\n",
    "def feature_extraction(file_path):\n",
    "    # iterate through all file\n",
    "        y, sr = librosa.load(file_path, mono=True, duration=30)\n",
    "            # remove leading and trailing silence\n",
    "        y, index = librosa.effects.trim(y)\n",
    "        # chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "        rmse = librosa.feature.rms(y=y)\n",
    "        spec_cent = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "        spec_bw = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
    "        rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
    "        zcr = librosa.feature.zero_crossing_rate(y)\n",
    "        mfcc = librosa.feature.mfcc(y=y, sr=sr,n_mfcc=39)\n",
    "        to_append = f'{file},{np.mean(rmse)},{np.mean(spec_cent)},{np.mean(spec_bw)},{np.mean(rolloff)},{np.mean(zcr)}'\n",
    "        for e in mfcc:\n",
    "            to_append += f',{np.mean(e)}'\n",
    "        \n",
    "        writeCsv(to_append)\n",
    "        return to_append\n",
    "\n",
    "to_append =[]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "path ='./Data/Person_data/'\n",
    "\n",
    "for file in os.listdir(path):\n",
    "    # print(file)\n",
    "    file_path = f\"{path}\\{file}\"  \n",
    "    data = feature_extraction(file_path)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extraction_array(file_path):\n",
    "    to_append =[]\n",
    "    # iterate through all file\n",
    "    y, sr = librosa.load(file_path, mono=True, duration=30)\n",
    "        # remove leading and trailing silence\n",
    "    y, index = librosa.effects.trim(y)\n",
    "    # chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "    rmse = librosa.feature.rms(y=y)\n",
    "    spec_cent = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "    spec_bw = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
    "    rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
    "    zcr = librosa.feature.zero_crossing_rate(y)\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr,n_mfcc=39)\n",
    "    to_append.append(np.mean(rmse))\n",
    "    to_append.append(np.mean(spec_cent))\n",
    "    to_append.append(np.mean(spec_bw))\n",
    "    to_append.append(np.mean(rolloff))\n",
    "    to_append.append(np.mean(zcr))\n",
    "    for e in mfcc:\n",
    "        to_append.append(np.mean(e))\n",
    "    return to_append\n",
    "    \n",
    "    \n",
    "def preProcessing(csvName):\n",
    "    data = pd.read_csv(csvName)\n",
    "    audioName = data['filename']\n",
    "    speakerNumber = []\n",
    "    for i in range(len(audioName)):\n",
    "        speakerLetter = audioName[i][0]\n",
    "        if speakerLetter == \"A\":\n",
    "            speakerLetter = \"0\"\n",
    "        elif speakerLetter ==\"H\":\n",
    "            speakerLetter=\"1\"\n",
    "        elif speakerLetter == \"M\":\n",
    "            speakerLetter = \"2\"\n",
    "        elif speakerLetter ==\"Y\":\n",
    "            speakerLetter = \"3\"\n",
    "        else:\n",
    "            speakerLetter = \"4\"\n",
    "        speakerNumber.append(speakerLetter)\n",
    "\n",
    "    data = data.drop(['filename'],axis=1)\n",
    "\n",
    "\n",
    "    print(data.tail())\n",
    "    \n",
    "    return data, speakerNumber\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Speaker Recognition***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         rmse  spectral_centroid  spectral_bandwidth      rolloff  \\\n",
      "107  0.036961         900.262590         1228.633450  1710.715110   \n",
      "108  0.030798        1110.509419         1415.479838  2223.205344   \n",
      "109  0.043172        1029.468179         1322.851465  1998.239840   \n",
      "110  0.039588        1086.552395         1351.697446  2114.756303   \n",
      "111  0.029859         916.739124         1247.753847  1742.170715   \n",
      "\n",
      "     zero_crossing_rate       mfcc1       mfcc2      mfcc3      mfcc4  \\\n",
      "107            0.035929 -384.608643  144.547806   8.870942  20.455149   \n",
      "108            0.047576 -377.867615  147.641052  12.861173  29.303251   \n",
      "109            0.039006 -368.788727  147.944244   3.276975  19.193602   \n",
      "110            0.046777 -375.518097  142.554230   7.776324  18.943033   \n",
      "111            0.038239 -399.210754  149.685547  15.412180  12.311265   \n",
      "\n",
      "         mfcc5  ...    mfcc30    mfcc31    mfcc32    mfcc33    mfcc34  \\\n",
      "107  17.201056  ... -5.936404 -3.372059 -6.162612 -3.362956 -1.793169   \n",
      "108   7.407220  ... -3.957625 -5.848854 -5.028358 -0.060326 -2.647815   \n",
      "109  12.868071  ... -4.059534 -1.041569 -4.420043 -5.923615 -4.035215   \n",
      "110  11.607146  ... -5.287860 -3.281466 -3.859667 -1.042347 -2.691088   \n",
      "111  11.929899  ... -7.382219 -4.504726 -4.729310 -2.622808 -4.449813   \n",
      "\n",
      "       mfcc35    mfcc36    mfcc37    mfcc38    mfcc39  \n",
      "107 -2.867525 -2.074337  0.981576 -5.124632  0.422005  \n",
      "108 -2.938207 -2.298795 -0.090306 -5.299748  4.521146  \n",
      "109 -2.478376 -6.182919  0.487664 -5.075006 -3.532316  \n",
      "110 -1.899741  0.858136  1.705751 -3.368692 -0.251211  \n",
      "111 -4.060353 -3.073968 -0.262104 -3.486023  1.192688  \n",
      "\n",
      "[5 rows x 44 columns]\n"
     ]
    }
   ],
   "source": [
    "data, number = preProcessing(\"data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= np.array(data)\n",
    "\n",
    "y=np.asarray(number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=123\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model= svm.SVC(kernel='linear' , C=0.09)\n",
    "svm_model.fit(X_train, y_train) \n",
    "\n",
    "y_pred = svm_model.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['3']\n"
     ]
    }
   ],
   "source": [
    "testing = feature_extraction_array('./records/A_Random (6).wav')\n",
    "y_predict = svm_model.predict([testing])\n",
    "\n",
    "\n",
    "\n",
    "print(y_predict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train model accuracy = 1e+02 %\n",
      "  Test model accuracy = 91.3 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "y_pred_t = svm_model.predict(X_train)\n",
    "accuracy_t = metrics.accuracy_score(y_train,y_pred_t)\n",
    "\n",
    "\n",
    "print(f\"  Train model accuracy = {100* accuracy_t:.3} %\")\n",
    "accuracy = metrics.accuracy_score(y_test,y_pred)\n",
    "\n",
    "\n",
    "print(f\"  Test model accuracy = {100* accuracy:.3} %\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Plot  SVM***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Spoken Digit Recognition***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f544ce1a915a9875fad91c894e2c0bcad4b7a79945aa6027ef3ad27810072aa6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
